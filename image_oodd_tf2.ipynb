{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_oodd_tf2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOiSMFRqG6w8n5pe9qSzD7K"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7GWaIta6VjCe"},"source":["Import"]},{"cell_type":"code","metadata":{"id":"mgNFfoxSVOWK","executionInfo":{"status":"ok","timestamp":1615886463148,"user_tz":-540,"elapsed":3546,"user":{"displayName":"정용기","photoUrl":"","userId":"18035379839860346044"}}},"source":["import tensorflow as tf\r\n","import tensorflow.keras.backend as K\r\n","import os\r\n","import time\r\n","import argparse\r\n","from tensorflow.keras import Model, Sequential, metrics, optimizers\r\n","import numpy as np\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from sklearn import metrics\r\n","from tensorflow.keras.applications import VGG19\r\n","from tensorflow.keras import Model, Sequential\r\n","from tensorflow.keras.layers import InputLayer, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape\r\n","from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D,\\\r\n","                                    MaxPooling2D, UpSampling2D, GlobalAveragePooling2D,\\\r\n","                                    Layer, Lambda, Flatten, Reshape, Conv2DTranspose,\\\r\n","                                    Activation, LeakyReLU, Dropout, InputLayer, ReLU\r\n","\r\n","from tensorflow.keras import initializers\r\n","from tqdm import tqdm_notebook, tqdm\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import math\r\n","from glob import glob\r\n","from PIL import Image\r\n","import csv\r\n","import shutil\r\n","tf.random.set_seed(1234)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBZWr-xsVw9v"},"source":["Dataset 설정"]},{"cell_type":"code","metadata":{"id":"tpSjA09vVo0v"},"source":["## augmentation and normalization for training\r\n","def random_aug(img) :\r\n","    lower=0.8\r\n","    upper=1.2\r\n","    img = tf.image.random_contrast(img, lower, upper)\r\n","    img /= 255\r\n","    return img\r\n","\r\n","## normalization for validation and test\r\n","def test_norm(img) :\r\n","    img /= 255\r\n","    return img\r\n","\r\n","## dataset \r\n","def load_dataset(batch_size=256):\r\n","    ## size\r\n","    IMG_HEIGHT = 64\r\n","    IMG_WIDTH = 64\r\n","    \r\n","    ## path \r\n","    ### 하부 dir 구조 : normal/in_distribution_class_name/img_name, novel/out_of_distribution_class_name/img_name\r\n","    train_dir = \"path/to/train\"\r\n","    val_dir = \"path/to/val\"\r\n","    test_dir = \"path/to/test\"\r\n","\r\n","    ## ImageDataGenerator 정의\r\n","    ### train은 여러 augmentation, test는 기본 normalization만 적용\r\n","    train_image_generator = ImageDataGenerator(preprocessing_function=random_aug, rotation_range=2, width_shift_range=1.0,\\\r\n","                                   height_shift_range=1.0, brightness_range=(0.8,1.2), zoom_range=0.02,\\\r\n","                                   fill_mode='nearest', horizontal_flip=True,\\\r\n","                                   vertical_flip=True)\r\n","    \r\n","    test_image_generator = ImageDataGenerator(preprocessing_function=test_norm)\r\n","\r\n","    train_dataset = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                             directory=train_dir,\r\n","                                                             shuffle=True,\r\n","                                                             target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                             class_mode = 'categorical',\r\n","                                                             interpolation = 'bicubic'\r\n","                                                               )\r\n","    \r\n","    val_dataset = test_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                             directory=val_dir,\r\n","                                                             shuffle=False,\r\n","                                                             target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                             class_mode = 'categorical',\r\n","                                                             interpolation = 'bicubic'\r\n","                                                               )\r\n","\r\n","    test_dataset = test_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                            directory=test_dir,\r\n","                                                            shuffle=False,\r\n","                                                            target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                            class_mode = 'categorical',\r\n","                                                            interpolation = 'bicubic'\r\n","                                                           )\r\n","\r\n","    ## normal, novel로 class 2개\r\n","    nb_classes = 2 \r\n","    return train_dataset, val_dataset, test_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ldjN2A_V6dN"},"source":["Display function"]},{"cell_type":"code","metadata":{"id":"qruItGFkV5Jd"},"source":["def display_image(image_set, recon_set) :\r\n","    fig=plt.figure(figsize=(25, 25))\r\n","    for i, a in enumerate(image_set) :\r\n","        fig.add_subplot(10, 10, 2*i+1)\r\n","        plt.imshow(a)\r\n","        fig.add_subplot(10, 10, 2*i+2)\r\n","        plt.imshow(recon_set[i])\r\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jsuWvbCkV9EO"},"source":["Loss 정의"]},{"cell_type":"code","metadata":{"id":"dAQOIBfwV-W7"},"source":["## KLD 정의\r\n","kl = tf.keras.losses.KLDivergence()\r\n","\r\n","## Contextual Loss 정의\r\n","def contextual_loss(x1, y1, loss_type, h=0.1, train=True):\r\n","    cx_loss = 0 if train else []\r\n","    for x, y in zip(x1, y1):\r\n","        if loss_type == 'cl_cosine':\r\n","            d = cosine_dist(x, y)\r\n","        elif loss_type == 'cl_l2':\r\n","            d = l2_dist(x, y)\r\n","        else:\r\n","            d = l1_dist(x, y)\r\n","            \r\n","        d_min = K.min(d, axis=2, keepdims=True)        # (N, H*W, 1)\r\n","        # Eq (2)\r\n","        d_tilde = d / (d_min + 1e-5)\r\n","        # Eq(3)\r\n","        w = K.exp((1 - d_tilde) / h)\r\n","        # Eq(4)\r\n","        cx_ij = w / K.sum(w, axis=2, keepdims=True)       # (N, H*W, H*W)\r\n","        # Eq (1)\r\n","        cx = K.mean(K.max(cx_ij, axis=1), axis=1)  # (N, )\r\n","        if train:\r\n","            cx_loss += K.mean(-K.log(cx))\r\n","        else:\r\n","            cx_loss.append(-K.log(cx))    \r\n","    return cx_loss\r\n","\r\n","def cosine_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","    \r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","    \r\n","    y_mu = K.mean(y_vec, axis=[0, 2, 3], keepdims=True)\r\n","    \r\n","    x_centered = x_vec - y_mu\r\n","    y_centered = y_vec - y_mu\r\n","    \r\n","    x_normalized = x_centered / tf.norm(x_centered, ord=2, axis=1, keepdims=True)\r\n","    y_normalized = y_centered / tf.norm(y_centered, ord=2, axis=1, keepdims=True)\r\n","\r\n","    ############\r\n","    x_normalized = tf.reshape(x_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","    y_normalized = tf.reshape(y_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","\r\n","    x_normalized = tf.transpose(x_normalized, perm=[0,2,1])\r\n","    \r\n","    cosine_sim = tf.matmul(x_normalized, y_normalized)\r\n","\r\n","    d = 1 - cosine_sim \r\n","    \r\n","    return d\r\n","\r\n","def l2_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","    \r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","\r\n","    x_vec = tf.reshape(x_vec, [N, C, -1])\r\n","    y_vec = tf.reshape(y_vec, [N, C, -1])\r\n","    \r\n","    ### TODO ###\r\n","#     x_s = torch.sum(x_vec ** 2, dim=1, keepdim=True)\r\n","#     y_s = torch.sum(y_vec ** 2, dim=1, keepdim=True)\r\n","    \r\n","    x_s = K.sum(x_vec ** 2, axis=1, keepdims=True)\r\n","    y_s = K.sum(y_vec ** 2, axis=1, keepdims=True)\r\n","    ############\r\n","    \r\n","    A = tf.transpose(y_vec, perm=[0,2,1]) @ x_vec\r\n","    B = tf.transpose(x_s, perm=[0,2,1])\r\n","    \r\n","    dist = y_s - 2 * A + B\r\n","    dist = tf.transpose(dist, perm=[0,2,1])\r\n","    dist = K.clip(dist, min_value=0., max_value=100000)\r\n","    return dist\r\n","\r\n","def l1_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","    \r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","\r\n","    x_vec = tf.reshape(x_vec, [N, C, -1])\r\n","    y_vec = tf.reshape(y_vec, [N, C, -1])\r\n","\r\n","    dist = tf.expand_dims(x_vec, axis=2) - tf.expand_dims(y_vec, axis=3)\r\n","\r\n","    dist = K.sum(K.abs(dist), axis=1)\r\n","\r\n","    dist = tf.transpose(dist, perm=[0,2,1])\r\n","\r\n","    dist = K.clip(dist, min_value=0., max_value=100000)\r\n","    \r\n","    return dist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_zLUolSVV_-5"},"source":["Test 함수 정의"]},{"cell_type":"code","metadata":{"id":"-a2_mrljWB93"},"source":["def diff(test_dataset, model, loss_type, selected_pm_layers):\r\n","    diffs_total = [[] for _ in selected_pm_layers]\r\n","    labels =[] \r\n","    diffs = []\r\n","    file_path = test_dataset.filepaths\r\n","    crit = contextual_loss   \r\n","\r\n","    for _ in tqdm(range(len(test_dataset))):\r\n","        image_batch, label_batch = test_dataset.next()\r\n","        \r\n","        mean, log_var, latent_z, recon = model(image_batch, training=False)\r\n","        \r\n","        targets = model.classifier(image_batch)\r\n","        recon_features = model.classifier(recon)\r\n","        \r\n","        temp = crit(recon_features, targets, train=False, loss_type=loss_type)\r\n","        \r\n","        for diffs_tmp, tmp in zip(diffs_total, temp):\r\n","            diffs_tmp.append(tmp) \r\n","        labels.extend(np.argmax(label_batch, axis=1).tolist())\r\n","    \r\n","    display_image(image_batch, recon)\r\n","    \r\n","    diffs = [K.concatenate(i, axis=0) for i in diffs_total]\r\n","    \r\n","    return diffs, labels, file_path\r\n","    \r\n","def testing(test_diff, label, file_path):\r\n","    from collections import defaultdict\r\n","    loss = 0\r\n","    for i in test_diff:\r\n","        loss += i\r\n","    if len(set(label)) > 1 :\r\n","        fprs, tprs, threshold = metrics.roc_curve(label, loss, pos_label=1)\r\n","        auc, tnr_at_tpr98, th_loss = get_curve(loss,label,normal_label=0)\r\n","        print('threshold : ', th_loss)\r\n","        FN_path=''\r\n","        FP_path=''\r\n","        FP_metric = defaultdict(list)\r\n","        loss_count = 0 \r\n","        for i_path, i_loss in zip(file_path, loss.numpy()):\r\n","            if i_loss >= th_loss and i_path.split('/')[-3]=='normal' :\r\n","                FN_path += (i_path+'\\n\\n')\r\n","                loss_count+=1\r\n","            elif i_loss < th_loss and i_path.split('/')[-3]=='novel' :\r\n","                FP_path += (i_path+'\\n\\n')\r\n","                FP_metric[i_path.split('/')[-2]].append(i_path.split('/')[-1])\r\n","        print('과검 :',loss_count)\r\n","        for ng_name in FP_metric.keys() :\r\n","            print('미검 '+ng_name, len(FP_metric[ng_name]) )\r\n","        auc_ori = metrics.auc(fprs, tprs)\r\n","        auroc_odin = metrics.roc_auc_score(label, loss)\r\n","        aupr_in = metrics.average_precision_score(label,loss)\r\n","        aupr_out = metrics.average_precision_score(-1 * np.array(label) + 1, 1. - loss)\r\n","    else : \r\n","        auc_ori, auc, tnr_at_tpr98, auroc_odin, aupr_in, aupr_out = 0, 0, 0, 0, 0, 0\r\n","    val_loss = np.mean(loss)   \r\n","    return auc_ori, auc, tnr_at_tpr98, auroc_odin, aupr_in, aupr_out, val_loss\r\n","\r\n","## normal, novel loss 구분\r\n","def normal_novel(loss, label, normal_label=1):\r\n","    loss = np.array(loss)\r\n","    label = np.array(label)\r\n","    check = (label == normal_label)\r\n","    normal_loss = loss[check]\r\n","    novel_loss = loss[~check]\r\n","    return normal_loss, novel_loss\r\n","\r\n","## auroc 및 성능 지표 계산 함수\r\n","def get_curve(loss, label, normal_label=1):\r\n","    normal, novel = normal_novel(loss, label, normal_label)\r\n","    tp, fp, tnr_at_tpr98 = [], [], []\r\n","    normal, novel = np.sort(normal)[::-1], np.sort(novel)[::-1] # 역순으로 변경\r\n","    end = np.max([np.max(normal), np.max(novel)])\r\n","    normal = end - normal # 추가 해야함\r\n","    novel = end - novel    # 추가 해야함\r\n","    start = np.min([np.min(normal), np.min(novel)])\r\n","    num_k, num_n = normal.shape[0], novel.shape[0]\r\n","    recall_k = 0.98\r\n","    pred_k_num = math.ceil(num_k*recall_k)\r\n","    threshold_loss = (end-normal[-pred_k_num] + end-normal[-pred_k_num-1])/2\r\n","    \r\n","    tp = -np.ones([num_k+num_n+1], dtype=int)\r\n","    fp = -np.ones([num_k+num_n+1], dtype=int)\r\n","    tp[0], fp[0] = num_k, num_n\r\n","    k, n = 0, 0\r\n","    for l in range(num_k+num_n):\r\n","        if k == num_k:\r\n","            tp[l+1:] = tp[l]\r\n","            fp[l+1:] = np.arange(fp[l]-1, -1, -1)\r\n","            break\r\n","        elif n == num_n:\r\n","            tp[l+1:] = np.arange(tp[l]-1, -1, -1)\r\n","            fp[l+1:] = fp[l]\r\n","            break\r\n","        else:\r\n","            if novel[n] < normal[k]:\r\n","                n += 1\r\n","                tp[l+1] = tp[l]\r\n","                fp[l+1] = fp[l] - 1\r\n","            else:\r\n","                k += 1\r\n","                tp[l+1] = tp[l] - 1\r\n","                fp[l+1] = fp[l]\r\n","    tpr95_pos = np.abs(tp / num_k - recall_k).argmin()\r\n","    tnr_at_tpr98 = 1. - fp[tpr95_pos] / num_n\r\n","    tpr = tp/num_k\r\n","    fpr = fp/num_n\r\n","    from sklearn import metrics\r\n","    auroc = metrics.auc(fpr, tpr)\r\n","    return auroc, tnr_at_tpr98, threshold_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"971SJiDxWF9n"},"source":["모델 정의"]},{"cell_type":"code","metadata":{"id":"whgP7CLDWEBy"},"source":["class DFCVAE(tf.keras.Model):\r\n","    def __init__(self, latent_dim: int, net_type: str='conv', selected_pm_layers=[]):\r\n","        super(DFCVAE, self).__init__()\r\n","        self.latent_dim = latent_dim\r\n","        assert net_type in ['simple', 'conv']\r\n","#         inputs = tf.keras.Input(shape=(64, 64, 3))\r\n","        self.encoder_conv1 = Conv2D(32, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn1 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","\r\n","        self.encoder_conv2 = Conv2D(64, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn2 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","        \r\n","        self.encoder_conv3 = Conv2D(128, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn3 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","\r\n","        self.encoder_conv4 = Conv2D(256, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn4 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","    \r\n","        self.z_mean = Dense(self.latent_dim, name=\"z_mean\")\r\n","        self.z_log_var = Dense(self.latent_dim, name=\"z_log_var\")\r\n","        \r\n","        self.decoder_dense = Dense(4096)\r\n","        self.decoder_conv1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn1 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","        \r\n","        self.decoder_conv2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn2 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","        \r\n","        self.decoder_conv3 = Conv2D(32, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn3 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","\r\n","        self.decoder_conv4 = Conv2D(3, 3, strides=1, padding='same', activation='sigmoid', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.classifier = self.make_classifier(selected_pm_layers)\r\n","    \r\n","    def call(self, input_tensor, training=False):\r\n","        x = self.encoder_conv1(input_tensor)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn1(x, training=training)\r\n","        \r\n","        x = self.encoder_conv2(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn2(x, training=training)\r\n","        \r\n","        x = self.encoder_conv3(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn3(x, training=training)\r\n","        \r\n","        x = self.encoder_conv4(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn4(x, training=training)\r\n","        \r\n","        x = Flatten()(x)\r\n","        z_mean = self.z_mean(x)\r\n","        z_log_var = self.z_log_var(x)\r\n","        z = self.reparameterize(z_mean, z_log_var, training)\r\n","        \r\n","        x = self.decoder_dense(z)\r\n","        x = ReLU()(x)\r\n","        \r\n","        x = Reshape((4, 4, 256))(x)\r\n","        \r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv1(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn1(x, training=training)\r\n","        \r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv2(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn2(x, training=training)\r\n","\r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv3(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn3(x, training=training)\r\n","\r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv4(x)\r\n","\r\n","        return z_mean, z_log_var, z, x\r\n","    \r\n","    \r\n","    def make_classifier(self, selected_pm_layers):\r\n","        pm = VGG19(include_top=False, weights='imagenet')\r\n","\r\n","        outputs = [pm.get_layer(l).output for l in selected_pm_layers]\r\n","        classifier = Model(pm.input, outputs)\r\n","    \r\n","        return classifier\r\n","    \r\n","    def reparameterize(self, mean, logvar, training):\r\n","        if training :\r\n","            eps = tf.random.normal(shape=tf.shape(mean))\r\n","        else :\r\n","            eps = tf.random.normal(shape=tf.shape(mean), seed=0)\r\n","        return eps * tf.exp(logvar * .5) + mean "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-JMPcq5WIce"},"source":["Hyper-parameter 설정"]},{"cell_type":"code","metadata":{"id":"BL5TKQdYWLqn"},"source":["loss_type = \"cl_cosine\" ## loss type in ['cl_cosine', 'cl_l1', 'cl_l2']\r\n","latent_dim = 100 ## num of latent dim\r\n","num_epochs = 200 ## num of epoch\r\n","lr = 0.001 ## learning rate\r\n","batch_size = 32 ## batch size\r\n","log_dir = 'test_model' ## model file\r\n","\r\n","## parameter initializers\r\n","init1 = initializers.he_normal()\r\n","init2 = initializers.RandomNormal(stddev=0.015)\r\n","\r\n","## feature extractor \r\n","selected_pm_layers = ['block4_conv1', 'block5_conv1']\r\n","model = DFCVAE(latent_dim, net_type='conv', selected_pm_layers=selected_pm_layers)\r\n","model.classifier.trainable = False\r\n","optimizer = tf.keras.optimizers.Adam(lr)\r\n","crit = contextual_loss\r\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3SkJbrDWNKF"},"source":["Data Load"]},{"cell_type":"code","metadata":{"id":"ZvhJpZ-4WONY"},"source":["train_dataset, val_dataset, test_dataset = load_dataset(batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJG1D-ikWPU9"},"source":["Training"]},{"cell_type":"code","metadata":{"id":"Ipa_jayoWQtG"},"source":["best_tnr_tpr98 = 0\r\n","min_val_loss = 100\r\n","best_epoch = 0\r\n","for epoch in range(1, num_epochs + 1):\r\n","    t = time.time()\r\n","    kl_loss_list = []\r\n","    rc_loss_list = []\r\n","    \r\n","    for _ in tqdm(range(len(train_dataset))):\r\n","        train_x = train_dataset.next()[0]\r\n","        with tf.GradientTape() as tape:\r\n","            mean, log_var, z, reconstruction = model(train_x, training=True)\r\n","            h1_list = model.classifier(train_x)\r\n","            h2_list = model.classifier(reconstruction)\r\n","\r\n","            kl_loss = kl(tf.fill([z.shape[0], z.shape[1]],1.0),tf.nn.softmax(z,axis=1)) / z.shape[1]\r\n","            rc_loss = crit(h2_list, h1_list, train=True, loss_type=loss_type)\r\n","            total_loss = kl_loss + rc_loss\r\n","        grad = tape.gradient(total_loss, model.trainable_variables)\r\n","        optimizer.apply_gradients(zip(grad, model.trainable_variables))\r\n","\r\n","        kl_loss_list.append(kl_loss.numpy())\r\n","        rc_loss_list.append(rc_loss.numpy())\r\n","    kl_last_loss = np.mean(kl_loss_list)\r\n","    rc_last_loss = np.mean(rc_loss_list)\r\n","    display_image(train_x, reconstruction)\r\n","    \r\n","    print('Epoch {}, Loss1: {}, Loss2: {}, Remaining Time at Epochs: {:.2f}'.format(\r\n","            epoch, kl_last_loss, rc_last_loss, time.time() - t\r\n","        ))\r\n","    \r\n","    ## validation \r\n","    test_diff, label, file_path = diff(val_dataset, model, loss_type, selected_pm_layers)\r\n","    auc_ori, auc, tnr_at_tpr98, auroc_odin, aupr_in, aupr_out, val_loss = testing(test_diff, label, file_path)\r\n","    if val_loss < min_val_loss :\r\n","        min_val_loss = val_loss\r\n","        best_epoch = epoch\r\n","    print(best_epoch)\r\n","    model.save(\"./results/\"+log_dir+\"_oodd-{:03d}\".format(epoch))\r\n","    print('-------------validation_result--------------')\r\n","    print('auc_ori',auc_ori)\r\n","    print('auc',auc)\r\n","    print('tnr_at_tpr98',tnr_at_tpr98)\r\n","    print('aupr_in',aupr_in)\r\n","    print('aupr_out',aupr_out)\r\n","    print('val_loss',val_loss)\r\n","\r\n","    ## test\r\n","    test_diff, label, file_path = diff(test_dataset, model, loss_type, selected_pm_layers)\r\n","    auc_ori, auc, tnr_at_tpr98, auroc_odin, aupr_in, aupr_out, test_loss = testing(test_diff, label, file_path)\r\n","    print('-------------test_result--------------')\r\n","    print('auc_ori',auc_ori)\r\n","    print('auc',auc)\r\n","    print('tnr_at_tpr98',tnr_at_tpr98)\r\n","    print('aupr_in',aupr_in)\r\n","    print('aupr_out',aupr_out)\r\n","    print('test_loss',test_loss)\r\n","    print(best_epoch, min_val_loss)\r\n","    if best_tnr_tpr98 < tnr_at_tpr98 :\r\n","        best_tnr_tpr98 = tnr_at_tpr98\r\n","    \r\n","model.save(\"./results/\"+log_dir+\"_oodd_last\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"an5c-MnTWSD4"},"source":["Test"]},{"cell_type":"code","metadata":{"id":"9qTKM4gFWS9w"},"source":["loaded_model = tf.keras.models.load_model('path/to/model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ssOki_PWYvk"},"source":["test_dataset.reset()\r\n","tf.random.set_seed(1234)\r\n","np.random.seed(0)\r\n","test_diff, label, file_path = diff(test_dataset, loaded_model, loss_type, selected_pm_layers)\r\n","auc_ori, auc, tnr_at_tpr98, auroc_odin, aupr_in, aupr_out, test_loss = testing(test_diff, label, file_path)\r\n","print('auc_ori',auc_ori)\r\n","print('auc',auc)\r\n","print('tnr_at_tpr98',tnr_at_tpr98)\r\n","print('aupr_in',aupr_in)\r\n","print('aupr_out',aupr_out)\r\n","print('test_loss',test_loss)"],"execution_count":null,"outputs":[]}]}