{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_image_oodd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPK8E1ouxrx/zo5odwOdKuo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"miSX_OJMzJHS"},"source":["import tensorflow as tf\r\n","import tensorflow.keras.backend as K\r\n","import os\r\n","import time\r\n","import argparse\r\n","from tensorflow.keras import Model, Sequential, metrics, optimizers # modify hyemin\r\n","import numpy as np\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from sklearn import metrics\r\n","from tensorflow.keras.applications import VGG19\r\n","from tensorflow.keras import Model, Sequential\r\n","from tensorflow.keras.layers import InputLayer, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape\r\n","from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D,\\\r\n","                                    MaxPooling2D, UpSampling2D, GlobalAveragePooling2D,\\\r\n","                                    Layer, Lambda, Flatten, Reshape, Conv2DTranspose,\\\r\n","                                    Activation, LeakyReLU, Dropout, InputLayer, ReLU\r\n","\r\n","from tensorflow.keras import initializers\r\n","from tqdm import tqdm_notebook, tqdm\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import math\r\n","from glob import glob\r\n","from PIL import Image\r\n","import csv\r\n","import shutil\r\n","tf.random.set_seed(1234)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dumBzVPyzQoo"},"source":["def random_aug(img) :\r\n","    lower=0.8\r\n","    upper=1.2\r\n","#     img = tf.image.random_contrast(img, lower, upper)\r\n","#     noise = tf.random.normal(shape=tf.shape(img), mean=5.0, stddev=1, dtype=tf.float32)\r\n","#     img = tf.add(img, noise)\r\n","#     mean = [0.5692, 0.5692, 0.5692]\r\n","#     std = [0.3469, 0.3469, 0.3469]\r\n","    \r\n","    img /= 255\r\n","#     img -= mean\r\n","#     img /= std\r\n","    return img\r\n","def test_norm(img) :\r\n","#     mean = [0.5692, 0.5692, 0.5692]\r\n","#     std = [0.3469, 0.3469, 0.3469]\r\n","    img /= 255\r\n","#     img -= mean\r\n","#     img /= std\r\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_OF3sluazQrE"},"source":["def load_dataset(batch_size=256):\r\n","#     epochs = 15\r\n","    IMG_HEIGHT = 64\r\n","    IMG_WIDTH = 64\r\n","\r\n","    # data preparation\r\n","    #train_image_generator = IageDataGenerator(rescale=1./255) # Generator for our training data\r\n","#     train_dir = \"/home/data/LGC/X_ray/trainset/oodd_anode/0701/train0707/\"\r\n","#     val_dir = \"/home/data/LGC/X_ray/trainset/oodd_anode/0701/test0707/\"\r\n","    train_dir = \"/home/data/LGC/Cylindrical/ooddset/crop/train\"\r\n","    val_dir = \"/home/data/LGC/Cylindrical/ooddset/crop/val\"\r\n","    test_dir = \"/home/data/LGC/Cylindrical/ooddset/crop/test\"\r\n","\r\n","    train_image_generator = ImageDataGenerator(preprocessing_function=random_aug, rotation_range=2, width_shift_range=1.0,\\\r\n","                                   height_shift_range=1.0, brightness_range=(0.8,1.2), zoom_range=0.02,\\\r\n","                                   fill_mode='nearest', horizontal_flip=True,\\\r\n","                                   vertical_flip=True)\r\n","    \r\n","    test_image_generator = ImageDataGenerator(preprocessing_function=test_norm) # Generator for our validation data\r\n","\r\n","    train_dataset = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                             directory=train_dir,\r\n","                                                             shuffle=True,\r\n","                                                             target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                             class_mode = 'categorical',\r\n","                                                             interpolation = 'bicubic'\r\n","                                                               )\r\n","    \r\n","    val_dataset = test_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                             directory=val_dir,\r\n","                                                             shuffle=False,\r\n","                                                             target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                             class_mode = 'categorical',\r\n","                                                             interpolation = 'bicubic'\r\n","                                                               )\r\n","\r\n","    test_dataset = test_image_generator.flow_from_directory(batch_size=batch_size,\r\n","                                                            directory=test_dir,\r\n","                                                            shuffle=False,\r\n","                                                            target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n","                                                            class_mode = 'categorical',\r\n","                                                            interpolation = 'bicubic'\r\n","                                                           )\r\n","\r\n","    nb_classes = 2\r\n","    print('lgc ok') \r\n","    return train_dataset, val_dataset, test_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcJiyS5GzQtl"},"source":["kl = tf.keras.losses.KLDivergence()\r\n","def rel_perc_l1_loss(targets, recon_features, loss_type, train=True) :\r\n","    if train:\r\n","        rc_loss = 0\r\n","\r\n","        for h1, h2 in zip(targets, recon_features):\r\n","            h1 = K.batch_flatten(h1)\r\n","            h2 = K.batch_flatten(h2)\r\n","            h1 = (h1 - np.mean(h1, axis=-1, keepdims=True)) / np.std(h1, axis=-1, keepdims=True)\r\n","            h2 = (h2 - np.mean(h2, axis=-1, keepdims=True)) / np.std(h2, axis=-1, keepdims=True)\r\n","            rc_loss = rc_loss + K.mean(K.mean(K.abs(h1-h2)/(K.abs(h1)+1e-7), axis=-1))\r\n","            \r\n","    else:\r\n","        rc_loss = []\r\n","        \r\n","        for h1, h2 in zip(targets, recon_features):\r\n","            h1 = K.batch_flatten(h1)\r\n","            h2 = K.batch_flatten(h2)\r\n","            h1 = (h1 - np.mean(h1, axis=-1, keepdims=True)) / np.std(h1, axis=-1, keepdims=True)\r\n","            h2 = (h2 - np.mean(h2, axis=-1, keepdims=True)) / np.std(h2, axis=-1, keepdims=True)\r\n","            rc_loss.append(K.mean(K.abs(h1-h2)/(K.abs(h1)+1e-7), axis=1))\r\n","        \r\n","    return rc_loss\r\n","\r\n","def perceptual_loss(recon_features, targets, loss_type, train=True):\r\n","# #     for h1, h2, weight in zip(h1_list, h2_list, selected_pm_layer_weights):\r\n","\r\n","    if train:\r\n","        rc_loss = 0\r\n","\r\n","        for h1, h2 in zip(targets, recon_features):\r\n","            h1 = K.batch_flatten(h1)\r\n","            h2 = K.batch_flatten(h2)\r\n","            rc_loss = rc_loss + K.mean(K.square(h1 - h2), axis=-1)\r\n","#             rc_loss = rc_loss + K.mean(1-tf.keras.losses.cosine_similarity(h1, h2, axis=-1))\r\n","            \r\n","    else:\r\n","        rc_loss = []\r\n","        \r\n","        for h1, h2 in zip(targets, recon_features):\r\n","            h1 = K.batch_flatten(h1)\r\n","            h2 = K.batch_flatten(h2)\r\n","            rc_loss.append(K.mean(K.square(h1 - h2), axis=1))\r\n","#             rc_loss.append(K.mean(1-tf.keras.losses.cosine_similarity(h1, h2, axis=-1)))\r\n","#     rc_loss = 0 if train else []\r\n","#     for x, y in zip(x1, y1):\r\n","#         N, H, W, C = x.shape\r\n","\r\n","#         x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","#         y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","\r\n","#         y_mu = K.mean(y_vec, axis=[0, 2, 3], keepdims=True)\r\n","\r\n","#         x_centered = x_vec - y_mu\r\n","#         y_centered = y_vec - y_mu\r\n","\r\n","#         x_normalized = x_centered / tf.norm(x_centered, ord=2, axis=1, keepdims=True)\r\n","#         y_normalized = y_centered / tf.norm(y_centered, ord=2, axis=1, keepdims=True)\r\n","\r\n","#         ############\r\n","#         x_normalized = tf.reshape(x_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","#         y_normalized = tf.reshape(y_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","\r\n","#         x_normalized = tf.transpose(x_normalized, perm=[0,2,1])\r\n","\r\n","#         cosine_sim = tf.matmul(x_normalized, y_normalized)\r\n","    \r\n","    ############\r\n","#         d = 1 - cosine_sim\r\n","    \r\n","#         if train :\r\n","#             rc_loss += K.mean(d)\r\n","#         else : \r\n","#             rc_loss.append(K.mean(d))\r\n","        \r\n","    return rc_loss\r\n","\r\n","def cosine_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","    \r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","    \r\n","    y_mu = K.mean(y_vec, axis=[0, 2, 3], keepdims=True)\r\n","    \r\n","    x_centered = x_vec - y_mu\r\n","    y_centered = y_vec - y_mu\r\n","    \r\n","    x_normalized = x_centered / tf.norm(x_centered, ord=2, axis=1, keepdims=True)\r\n","    y_normalized = y_centered / tf.norm(y_centered, ord=2, axis=1, keepdims=True)\r\n","\r\n","    ############\r\n","    x_normalized = tf.reshape(x_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","    y_normalized = tf.reshape(y_normalized, [N, C, -1])                                # (N, C, H*W)\r\n","    \r\n","    ### TODO ### einsum 으로 bmm 대체 가능, 3D의 경우 matmul로 가능 -> Debug 필요\r\n","#     cosine_sim = torch.bmm(x_normalized.transpose(1, 2), y_normalized)\r\n","\r\n","    x_normalized = tf.transpose(x_normalized, perm=[0,2,1])\r\n","    \r\n","    cosine_sim = tf.matmul(x_normalized, y_normalized)\r\n","    \r\n","    ############\r\n","    d = 1 - cosine_sim \r\n","    \r\n","    return d\r\n","\r\n","def l2_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","    \r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","\r\n","    x_vec = tf.reshape(x_vec, [N, C, -1])\r\n","    y_vec = tf.reshape(y_vec, [N, C, -1])\r\n","    \r\n","    ### TODO ###\r\n","#     x_s = torch.sum(x_vec ** 2, dim=1, keepdim=True)\r\n","#     y_s = torch.sum(y_vec ** 2, dim=1, keepdim=True)\r\n","    \r\n","    x_s = K.sum(x_vec ** 2, axis=1, keepdims=True)\r\n","    y_s = K.sum(y_vec ** 2, axis=1, keepdims=True)\r\n","    ############\r\n","    \r\n","    A = tf.transpose(y_vec, perm=[0,2,1]) @ x_vec\r\n","    B = tf.transpose(x_s, perm=[0,2,1])\r\n","    \r\n","    dist = y_s - 2 * A + B\r\n","    dist = tf.transpose(dist, perm=[0,2,1])\r\n","    dist = K.clip(dist, min_value=0., max_value=100000)\r\n","    return dist\r\n","\r\n","def l1_dist(x, y):\r\n","    N, H, W, C = x.shape\r\n","#     print(x.shape)\r\n","    x_vec = tf.transpose(x, perm=[0,3,1,2])\r\n","    y_vec = tf.transpose(y, perm=[0,3,1,2])\r\n","#     print(x_vec.shape)\r\n","    x_vec = tf.reshape(x_vec, [N, C, -1])\r\n","    y_vec = tf.reshape(y_vec, [N, C, -1])\r\n","#     print(x_vec.shape)\r\n","    dist = tf.expand_dims(x_vec, axis=2) - tf.expand_dims(y_vec, axis=3)\r\n","#     dist = x_vec - y_vec\r\n","#     print(dist.shape)\r\n","#     dist = K.max(K.abs(dist), axis=1) + K.mean(K.abs(dist), axis=1)\r\n","    dist = K.sum(K.abs(dist), axis=1)\r\n","#     print(dist.shape)\r\n","    dist = tf.transpose(dist, perm=[0,2,1])\r\n","#     print(dist.shape)\r\n","    dist = K.clip(dist, min_value=0., max_value=100000)\r\n","    \r\n","    return dist\r\n","\r\n","def contextual_loss(x1, y1, loss_type, h=0.1, train=True):\r\n","    cx_loss = 0 if train else []\r\n","    for x, y in zip(x1, y1):\r\n","        if loss_type == 'cl_cosine':\r\n","            d = cosine_dist(x, y)\r\n","        elif loss_type == 'cl_l2':\r\n","            d = l2_dist(x, y)\r\n","        else:\r\n","            d = l1_dist(x, y)\r\n","            \r\n","        d_min = K.min(d, axis=2, keepdims=True)        # (N, H*W, 1)\r\n","        # Eq (2)\r\n","        d_tilde = d / (d_min + 1e-5)\r\n","        # Eq(3)\r\n","        w = K.exp((1 - d_tilde) / h)\r\n","        # Eq(4)\r\n","        cx_ij = w / K.sum(w, axis=2, keepdims=True)       # (N, H*W, H*W)\r\n","        # Eq (1)\r\n","        cx = K.mean(K.max(cx_ij, axis=1), axis=1)  # (N, )\r\n","        if train:\r\n","            cx_loss += K.mean(-K.log(cx))\r\n","        else:\r\n","            cx_loss.append(-K.log(cx))    \r\n","        ############\r\n","    return cx_loss\r\n","\r\n","def diff(test_dataset, model, loss_type, selected_pm_layers):\r\n","    diffs_total = [[] for _ in selected_pm_layers]\r\n","    labels =[] \r\n","    diffs = []\r\n","    diffs2 = []\r\n","    kl_loss_list = []\r\n","    file_path = test_dataset.filepaths\r\n","    if loss_type == 'pl':\r\n","        crit = perceptual_loss\r\n","    elif loss_type == 'pl2' :\r\n","        crit = rel_perc_l1_loss\r\n","    else:\r\n","        crit = contextual_loss   \r\n","\r\n","    for _ in tqdm(range(len(test_dataset))):\r\n","        image_batch, label_batch = test_dataset.next()\r\n","        \r\n","#         mean, log_var, latent_z, recon = model(image_batch, training=False)\r\n","        mean, log_var, latent_z, recon = model(image_batch, training=False)\r\n","#         feature_2, _, _ = model(recon, training=False)\r\n","#         for i in range(len(mean)) :\r\n","#             tmp_mean = tf.expand_dims(mean[i], 0)\r\n","#             tmp_log_var =  tf.expand_dims(log_var[i], 0)\r\n","        targets = model.classifier(image_batch)\r\n","        recon_features = model.classifier(recon)\r\n","        \r\n","#         temp = [x+y for (x,y) in zip(crit(recon_features, targets, train=False, loss_type=loss_type),\\\r\n","#                                      crit(feature_2, feature_1, train=False, loss_type=loss_type))]\r\n","        temp = crit(recon_features, targets, train=False, loss_type=loss_type)\r\n","        \r\n","        for diffs_tmp, tmp in zip(diffs_total, temp):\r\n","            diffs_tmp.append(tmp) \r\n","        diffs2.append((recon-image_batch))\r\n","        labels.extend(np.argmax(label_batch, axis=1).tolist())\r\n","    \r\n","    fig=plt.figure(figsize=(25, 25))\r\n","    for i, a in enumerate(image_batch) :\r\n","        fig.add_subplot(10, 10, 2*i+1)\r\n","        plt.imshow(a)\r\n","        fig.add_subplot(10, 10, 2*i+2)\r\n","        plt.imshow(recon[i])\r\n","    plt.show()\r\n","    \r\n","    diffs = [K.concatenate(i, axis=0) for i in diffs_total]\r\n","    \r\n","    return diffs, kl_loss_list, labels, file_path # modify hyemin\r\n","            # torch.cat이 list안에 있는 tesnor를 하나로 뭉쳐줌.\r\n","\r\n","    \r\n","def testing(test_diff, kl_loss_list, label, file_path):\r\n","#     test_diff2 = tf.reshape(test_diffv2, [test_diffv2.shape[0], -1]).numpy()\r\n","    from collections import defaultdict\r\n","#     test_diff2 = test_diffv2.reshape(test_diffv2.shape[0], -1)\r\n","    ##### ToDo #####\r\n","    loss = 0\r\n","    for i in test_diff:\r\n","        loss += i\r\n","    ################\r\n","#     loss += kl_loss_list\r\n","#     loss2 = (test_diff2**2).sum(axis=1)\r\n","#     df = pd.DataFrame({'label':label, 'loss':loss})\r\n","#     df.to_csv('sample_result.csv')\r\n","    #print('loss shape {}'.format(loss.shape()))\r\n","    #print('loss2 shape {}'.format(loss2.shape()))\r\n","    #print('label {}'.format(label))\r\n","    print(len(label), len(loss))\r\n","    try :\r\n","        fprs, tprs, threshold = metrics.roc_curve(label, loss, pos_label=1) # loss는 batchsize만큼만 들어감\r\n","    #     fprs2,tprs2, threshold2 = metrics.roc_curve(label, loss2, pos_label=1) # 여기는 총 test set 개수가 들어감\r\n","    #     print('threshold {}'.format(threshold))\r\n","    #     print('threshold2 {}'.format(threshold2))\r\n","        auc, tnr_at_tpr95, th_loss = get_curve(loss,label,normal_label=0)\r\n","        print('threshold : ', th_loss)\r\n","        FN_path=''\r\n","        FP_path=''\r\n","        FP_metric = defaultdict(list)\r\n","        loss_count = 0 \r\n","    #     th_loss = 1.56\r\n","        for i_path, i_loss in zip(file_path, loss.numpy()):\r\n","    #         print(i_path, i_loss, th_loss)\r\n","            if i_loss >= th_loss and i_path.split('/')[-3]=='normal' :\r\n","                FN_path += (i_path+'\\n\\n')\r\n","                loss_count+=1\r\n","    #             writer.add_text('FN_images', i_path, FN_count)\r\n","            elif i_loss < th_loss and i_path.split('/')[-3]=='novel' :\r\n","                FP_path += (i_path+'\\n\\n')\r\n","                FP_metric[i_path.split('/')[-2]].append(i_path.split('/')[-1])\r\n","        print('과검 :',loss_count)\r\n","        for ng_name in FP_metric.keys() :\r\n","            print('미검 '+ng_name, len(FP_metric[ng_name]) )\r\n","        auc_ori = metrics.auc(fprs, tprs)\r\n","        auroc_odin = metrics.roc_auc_score(label, loss)\r\n","        aupr_in = metrics.average_precision_score(label,loss)\r\n","    except : \r\n","        auc_ori, auc, tnr_at_tpr95, auroc_odin, aupr_in = 0, 0, 0, 0, 0\r\n","    val_loss = np.mean(loss)   \r\n","    return auc_ori, auc, tnr_at_tpr95, auroc_odin, aupr_in, val_loss\r\n","\r\n","\r\n","def normal_novel(loss, label, normal_label=1):\r\n","    loss = np.array(loss)\r\n","    label = np.array(label)\r\n","    check = (label == normal_label)\r\n","    normal_loss = loss[check]\r\n","    novel_loss = loss[~check]\r\n","    return normal_loss, novel_loss\r\n","\r\n","def get_curve(loss, label, normal_label=1):\r\n","    normal, novel = normal_novel(loss, label, normal_label)\r\n","    tp, fp, tnr_at_tpr95 = [], [], []\r\n","    normal, novel = np.sort(normal)[::-1], np.sort(novel)[::-1] # 역순으로 변경\r\n","    end = np.max([np.max(normal), np.max(novel)])\r\n","    normal = end - normal # 추가 해야함\r\n","    novel = end - novel    # 추가 해야함\r\n","    start = np.min([np.min(normal), np.min(novel)])\r\n","    num_k, num_n = normal.shape[0], novel.shape[0]\r\n","    recall_k = 0.98\r\n","    pred_k_num = math.ceil(num_k*recall_k)\r\n","    threshold_loss = (end-normal[-pred_k_num] + end-normal[-pred_k_num-1])/2\r\n","    \r\n","    tp = -np.ones([num_k+num_n+1], dtype=int)\r\n","    fp = -np.ones([num_k+num_n+1], dtype=int)\r\n","    tp[0], fp[0] = num_k, num_n\r\n","    k, n = 0, 0\r\n","    for l in range(num_k+num_n):\r\n","        if k == num_k:\r\n","            tp[l+1:] = tp[l]\r\n","            fp[l+1:] = np.arange(fp[l]-1, -1, -1)\r\n","            break\r\n","        elif n == num_n:\r\n","            tp[l+1:] = np.arange(tp[l]-1, -1, -1)\r\n","            fp[l+1:] = fp[l]\r\n","            break\r\n","        else:\r\n","            if novel[n] < normal[k]:\r\n","                n += 1\r\n","                tp[l+1] = tp[l]\r\n","                fp[l+1] = fp[l] - 1\r\n","            else:\r\n","                k += 1\r\n","                tp[l+1] = tp[l] - 1\r\n","                fp[l+1] = fp[l]\r\n","    tpr95_pos = np.abs(tp / num_k - recall_k).argmin()\r\n","    tnr_at_tpr95 = 1. - fp[tpr95_pos] / num_n\r\n","    tpr = tp/num_k\r\n","    fpr = fp/num_n\r\n","    from sklearn import metrics\r\n","    auroc = metrics.auc(fpr, tpr)\r\n","    #aupr_in = metrics.average_precision_score(labels, scores)\r\n","    #aupr_out = metrics.average_precision_score(-1 * labels + 1, 1 - scores)\r\n","    return auroc, tnr_at_tpr95, threshold_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qK8JRKkizQwJ"},"source":["class DFCVAE(tf.keras.Model):\r\n","    def __init__(self, latent_dim: int, net_type: str='conv', selected_pm_layers=[]):\r\n","        super(DFCVAE, self).__init__()\r\n","        self.latent_dim = latent_dim\r\n","        assert net_type in ['simple', 'conv']\r\n","#         inputs = tf.keras.Input(shape=(64, 64, 3))\r\n","        self.encoder_conv1 = Conv2D(32, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn1 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","\r\n","        self.encoder_conv2 = Conv2D(64, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn2 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","        \r\n","        self.encoder_conv3 = Conv2D(128, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn3 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","\r\n","        self.encoder_conv4 = Conv2D(256, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.encoder_bn4 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","        \r\n","#         self.encoder_conv5 = Conv2D(128, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","#         self.encoder_bn5 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","        \r\n","#         self.encoder_conv6 = Conv2D(512, 4, strides=(2, 2), padding=\"same\", kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","#         self.encoder_bn6 = BatchNormalization(momentum=0.9, epsilon=1e-5)\r\n","    \r\n","        self.z_mean = Dense(self.latent_dim, name=\"z_mean\")\r\n","        self.z_log_var = Dense(self.latent_dim, name=\"z_log_var\")\r\n","        \r\n","        self.decoder_dense = Dense(4096)\r\n","        self.decoder_conv1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn1 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","        \r\n","        self.decoder_conv2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn2 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","        \r\n","        self.decoder_conv3 = Conv2D(32, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.decoder_bn3 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","        \r\n","#         self.decoder_conv4 = Conv2D(32, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","#         self.decoder_bn4 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","\r\n","#         self.decoder_conv5 = Conv2D(16, 3, strides=1, padding='same', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","#         self.decoder_bn5 = BatchNormalization(momentum=0.9, epsilon=1e-3)\r\n","\r\n","        self.decoder_conv4 = Conv2D(3, 3, strides=1, padding='same', activation='sigmoid', kernel_initializer=init1,bias_initializer=initializers.Zeros())\r\n","        self.classifier = self.make_classifier(selected_pm_layers)\r\n","        \r\n","#         inputs = tf.keras.Input(shape=(64, 64, 3))\r\n","#         self.output = self.call(inputs)\r\n","#         self.dfc_vae = Model(inputs, self.output)\r\n","    \r\n","    def call(self, input_tensor, training=False):\r\n","        x = self.encoder_conv1(input_tensor)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn1(x, training=training)\r\n","        \r\n","        x = self.encoder_conv2(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn2(x, training=training)\r\n","        \r\n","        x = self.encoder_conv3(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn3(x, training=training)\r\n","        feature1 = x\r\n","        \r\n","        x = self.encoder_conv4(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.encoder_bn4(x, training=training)\r\n","        feature2 = x\r\n","        \r\n","#         x = self.encoder_conv5(x)\r\n","#         x = LeakyReLU(0.2)(x)\r\n","#         x = self.encoder_bn5(x, training=training)\r\n","        \r\n","#         x = self.encoder_conv6(x)\r\n","#         x = LeakyReLU(0.2)(x)\r\n","#         x = self.encoder_bn6(x, training=training)\r\n","        \r\n","        x = Flatten()(x)\r\n","        z_mean = self.z_mean(x)\r\n","        z_log_var = self.z_log_var(x)\r\n","        z = self.reparameterize(z_mean, z_log_var, training)\r\n","        feature3 = z\r\n","        \r\n","        x = self.decoder_dense(z)\r\n","        x = ReLU()(x)\r\n","        \r\n","        x = Reshape((4, 4, 256))(x)\r\n","        \r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv1(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn1(x, training=training)\r\n","        \r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv2(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn2(x, training=training)\r\n","\r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv3(x)\r\n","        x = LeakyReLU(0.2)(x)\r\n","        x = self.decoder_bn3(x, training=training)\r\n","        \r\n","#         x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","#         x = self.decoder_conv4(x)\r\n","#         x = LeakyReLU(0.2)(x)\r\n","#         x = self.decoder_bn4(x, training=training)\r\n","        \r\n","#         x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","#         x = self.decoder_conv5(x)\r\n","#         x = LeakyReLU(0.2)(x)\r\n","#         x = self.decoder_bn5(x, training=training)\r\n","\r\n","        x = UpSampling2D((2, 2), interpolation='nearest')(x)\r\n","        x = self.decoder_conv4(x)\r\n","\r\n","        return z_mean, z_log_var, z, x\r\n","    \r\n","    \r\n","    def make_classifier(self, selected_pm_layers):\r\n","        pm = VGG19(include_top=False, weights='imagenet')\r\n","\r\n","        outputs = [pm.get_layer(l).output for l in selected_pm_layers]\r\n","        classifier = Model(pm.input, outputs)\r\n","#         classifier = vgg_pretrained\r\n","#         for layer in classifier.layers :\r\n","#             layer.trainable = False\r\n","    \r\n","        return classifier\r\n","    \r\n","    def reparameterize(self, mean, logvar, training):\r\n","        if training :\r\n","            eps = tf.random.normal(shape=tf.shape(mean))\r\n","        else :\r\n","            eps = tf.random.normal(shape=tf.shape(mean), seed=0)\r\n","        return eps * tf.exp(logvar * .5) + mean "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjnOuiBVzQyl"},"source":["loss_type = \"cl_cosine\"\r\n","latent_dim = 100\r\n","num_epochs = 200\r\n","lr = 0.001\r\n","batch_size = 32\r\n","log_dir = 'cylindrical_cl_cosine_crop_64'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xoSjrPtSzQ1d"},"source":["init1 = initializers.he_normal()\r\n","init2 = initializers.RandomNormal(stddev=0.015)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-BmSXSozQ3l"},"source":["selected_pm_layers = ['block4_conv1', 'block5_conv1']\r\n","selected_pm_layer_weights = [1.0, 1.0, 1.0]\r\n","model = DFCVAE(latent_dim, net_type='conv', selected_pm_layers=selected_pm_layers)\r\n","# model.classifier.trainable = False\r\n","print(\"LGC import Test #1\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJloAigVzQ6G"},"source":["train_dataset, val_dataset, test_dataset = load_dataset(batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6S3VMbrzQ8h"},"source":["optimizer = tf.keras.optimizers.Adam(lr)\r\n","crit = contextual_loss\r\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNQmp_XmzQ_F"},"source":["def get_negative_sample(img) :\r\n","    H, W, C = tf.shape(img)\r\n","    \r\n","    H, W = tf.cast(H, tf.float32), tf.cast(W, tf.float32)\r\n","    erase_w = tf.cast(tf.random.uniform([], 0.2*W, 0.3*W), tf.int32)\r\n","    erase_h = tf.cast(tf.random.uniform([], 0.2*H, 0.3*H), tf.int32)\r\n","    start_x = tf.cast(tf.random.uniform([], 0, 0.7*W), tf.int32)\r\n","    start_y = tf.cast(tf.random.uniform([], 0, 0.7*H), tf.int32)\r\n","    erase_area = tf.cast(tf.random.uniform([erase_h, erase_w, 1], 0, 255, tf.int32), tf.float32)/255.\r\n","    erase_area = tf.concat([erase_area]*3, axis=-1)\r\n","    \r\n","    output_img = np.copy(img)\r\n","    output_img[start_y:start_y+erase_h, start_x:start_x+erase_w, :] = erase_area\r\n","    return output_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fzu40KcezRBn"},"source":["def negative_sampling(inp_batch) :\r\n","    output = []\r\n","    for img in inp_batch :\r\n","        output.append(get_negative_sample(img))\r\n","    return np.array(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_P6LxkFzRED"},"source":["kl = tf.keras.losses.KLDivergence()\r\n","best_tnr_tpr98 = 0\r\n","min_val_loss = 100\r\n","best_epoch = 0\r\n","for epoch in range(1, num_epochs + 1):\r\n","    t = time.time()\r\n","    kl_loss_list = []\r\n","    rc_loss_list = []\r\n","    rc_loss_list2 = []\r\n","    model.trainable=True\r\n","    model.classifier.trainable=False\r\n","    \r\n","    for _ in tqdm(range(len(train_dataset))):\r\n","        train_x = train_dataset.next()[0]\r\n","        negative_sample = negative_sampling(train_x)\r\n","        with tf.GradientTape() as tape:\r\n","#             mean, log_var, z, reconstruction = model(train_x, training=True)\r\n","            mean, log_var, z, reconstruction = model(train_x, training=True)\r\n","            _, _, _, reconstruction2 = model(negative_sample, training=True)\r\n","#             feature_2, _, _ = model(reconstruction, training=True)\r\n","#             noise = tf.random.normal(shape=tf.shape(train_x), mean=0, stddev=0.05, dtype=tf.float32)\r\n","            h1_list = model.classifier(train_x)\r\n","            h2_list = model.classifier(reconstruction)\r\n","            h3_list = model.classifier(negative_sample)\r\n","            h4_list = model.classifier(reconstruction2)\r\n","            kl_loss = kl(tf.fill([z.shape[0], z.shape[1]],1.0),tf.nn.softmax(z,axis=1)) / z.shape[1]\r\n","#             kl_loss = kl(tf.nn.softmax(z,axis=1),\\\r\n","#                          tf.nn.softmax(tf.random.normal(shape=tf.shape(z), mean=0.0, stddev=0.00001),axis=1)) / z.shape[1]\r\n","#             kl_loss = 1 + log_var - tf.square(mean) - tf.exp(log_var)\r\n","#             kl_loss = tf.reduce_mean(kl_loss)\r\n","#             kl_loss *= -0.5\r\n","#             kl_loss = tf.reduce_mean(-0.5*tf.reduce_sum(1 + log_var - tf.square(mean) - tf.exp(log_var), 1))\r\n","#             rc_loss2 = tf.keras.losses.MSE(train_x, reconstruction)\r\n","#             rc_loss2 = crit(feature_2, feature_1, train=True, loss_type=loss_type)\r\n","            rc_loss1 = crit(h2_list, h1_list, train=True, loss_type=loss_type)\r\n","            rc_loss2 = crit(h4_list, h3_list, train=True, loss_type=loss_type)\r\n","            rc_loss3 = crit(h4_list, h1_list, train=True, loss_type=loss_type)\r\n","            rc_loss4 = crit(h2_list, h3_list, train=True, loss_type=loss_type)\r\n","#             rc_loss = (rc_loss1+rc_loss3) - 0.1/(rc_loss1+rc_loss3) * (rc_loss2+rc_loss4)\r\n","            rc_loss = (rc_loss1+rc_loss3) / (rc_loss2+rc_loss4)\r\n","            p2p_loss = K.mean((reconstruction-train_x)**2)\r\n","            total_loss = kl_loss + rc_loss\r\n","        grad = tape.gradient(total_loss, model.trainable_variables)\r\n","        optimizer.apply_gradients(zip(grad, model.trainable_variables))\r\n","\r\n","        kl_loss_list.append(kl_loss.numpy())\r\n","        rc_loss_list.append(rc_loss.numpy())\r\n","        rc_loss_list2.append(p2p_loss.numpy())\r\n","    kl_last_loss = np.mean(kl_loss_list)\r\n","    rc_last_loss = np.mean(rc_loss_list)\r\n","    rc_loss_list2 = np.mean(rc_loss_list2)\r\n","    \r\n","    fig=plt.figure(figsize=(25, 25))\r\n","    for i, a in enumerate(train_x) :\r\n","        fig.add_subplot(10, 10, 2*i+1)\r\n","        plt.imshow(a)\r\n","        fig.add_subplot(10, 10, 2*i+2)\r\n","        plt.imshow(reconstruction[i])\r\n","    plt.show()\r\n","    \r\n","    model.trainable=False\r\n","    print('Epoch {}, Loss1: {}, Loss2: {}, Loss3: {},  Remaining Time at Epochs: {:.2f}'.format(\r\n","            epoch, kl_last_loss, rc_last_loss, rc_loss_list2, time.time() - t\r\n","        ))\r\n","    test_diff, test_diff2, label, file_path = diff(val_dataset, model, loss_type, selected_pm_layers)\r\n","    auc_ori, auc, tnr_at_tpr95, auroc_odin, aupr_in, val_loss = testing(test_diff, test_diff2, label, file_path)\r\n","    if val_loss < min_val_loss :\r\n","        min_val_loss = val_loss\r\n","        best_epoch = epoch\r\n","    print(best_epoch)\r\n","    model.save(\"./results/\"+log_dir+\"_oodd-{:03d}\".format(epoch))\r\n","    print('-------------validation_result--------------')\r\n","    print('auc_ori',auc_ori)\r\n","    print('auc',auc)\r\n","    print('tnr_at_tpr95',tnr_at_tpr95)\r\n","    print('aupr_in',aupr_in)\r\n","    print('val_loss',val_loss)\r\n","\r\n","    test_diff, test_diff2, label, file_path = diff(test_dataset, model, loss_type, selected_pm_layers)\r\n","    auc_ori, auc, tnr_at_tpr95, auroc_odin, aupr_in, test_loss = testing(test_diff, test_diff2, label, file_path)\r\n","    print('-------------test_result--------------')\r\n","    print('auc_ori',auc_ori)\r\n","    print('auc',auc)\r\n","    print('tnr_at_tpr95',tnr_at_tpr95)\r\n","    print('aupr_in',aupr_in)\r\n","    print('test_loss',test_loss)\r\n","    print(best_epoch, min_val_loss)\r\n","    if best_tnr_tpr98 < tnr_at_tpr95 :\r\n","        best_tnr_tpr98 = tnr_at_tpr95\r\n","    \r\n","model.save(\"./results/\"+log_dir+\"_oodd_last\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jfzW5AczRGo"},"source":["loaded_model = tf.keras.models.load_model('results/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNo8vfbuzRJP"},"source":["test_dataset.reset()\r\n","tf.random.set_seed(1234)\r\n","np.random.seed(0)\r\n","test_diff, test_diff2, label, file_path = diff(test_dataset, loaded_model, loss_type, selected_pm_layers)\r\n","auc_ori, auc, tnr_at_tpr95, auroc_odin, aupr_in, val_loss = testing(test_diff, test_diff2, label, file_path)\r\n","print('auc_ori',auc_ori)\r\n","print('auc',auc)\r\n","print('tnr_at_tpr95',tnr_at_tpr95)\r\n","print('aupr_in',aupr_in)\r\n","print('val_loss',val_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XS36ai57zRLp"},"source":["from glob import glob\r\n","from PIL import Image\r\n","import csv\r\n","import shutil\r\n","import cv2\r\n","inference_set = glob(\"\")\r\n","len(inference_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqKl2XWmzRN6"},"source":["tf.random.set_seed(1234)\r\n","\r\n","count = 0 \r\n","loss_list = []\r\n","true_list = []\r\n","plt.figure(figsize = (20,20))\r\n","test_dataset.reset()\r\n","tf.random.set_seed(1234)\r\n","np.random.seed(0)\r\n","for img in tqdm_notebook(inference_set) :\r\n","    tmp_img = np.array(Image.open(img).convert('RGB').resize((64,64), Image.BICUBIC), dtype=np.float32)/255.\r\n","    tmp_img = np.expand_dims(tmp_img, 0)\r\n","    _, _, z, reconstruction = loaded_model(tmp_img, training=False)\r\n","    \r\n","    h1_list = loaded_model.classifier(tmp_img)\r\n","    h2_list = loaded_model.classifier(reconstruction)\r\n","    \r\n","    rc_loss = crit(h2_list, h1_list, train=False, loss_type=loss_type)\r\n","    loss = np.sum(rc_loss)\r\n","#     if loss >=1.67 and img.split('/')[-3]=='normal' :\r\n","    if loss>0.41 :\r\n","        pred = 'novel' \r\n","    else :\r\n","        pred = 'normal'\r\n","    true = img.split('/')[-3]\r\n","    \r\n","#     if (true == 'normal') and 0.08 <= loss :\r\n","#     if  0.12 < loss <= 0.18 :\r\n","    loss_list.append(loss)\r\n","    true_list.append(true)\r\n","    count+=1\r\n","#         ax = plt.subplot(6,3,count)\r\n","#         plt.imshow(np.concatenate([tmp_img[0],reconstruction[0]], axis=1), cmap='gray')\r\n","#         ax.set_title((true,str(loss)))\r\n","#         plt.axis('off')\r\n","#         if count==12 : break\r\n","plt.show()\r\n","#         print(count, true, pred, loss, img.split('/')[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rU35IbSzpjf"},"source":["ok_loss = np.array(loss_list)[np.array(true_list)=='normal']\r\n","ng_loss = np.array(loss_list)[np.array(true_list)=='novel']\r\n","len(ok_loss), len(ng_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I21LFqMuzpmJ"},"source":["plt.hist(ok_loss, bins=20, density=True, alpha=0.7, histtype='stepfilled', color='skyblue')\r\n","plt.hist(ng_loss, bins=20, density=True, alpha=0.3, histtype='stepfilled', color='red')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XM5y5Weczw7L"},"source":["for img in np.array(inference_set)[(np.array(true_list)=='normal')&(np.array(loss_list)>0.5)] :\r\n","    plt.imshow(Image.open(img), cmap='gray')\r\n","    plt.show()"],"execution_count":null,"outputs":[]}]}